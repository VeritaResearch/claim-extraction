{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from trl import KTOConfig, KTOTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_dataset = load_dataset(\"trl-lib/kto-mix-14k\", split=\"train\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "train_dataset"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion', 'label'],\n",
       "    num_rows: 13500\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "cache_dir = \"../assets/pretrained-models\"\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, cache_dir=cache_dir, use_safetensors=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path, cache_dir=cache_dir, use_safetensors=True, padding_side=\"left\"\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI agent used to determine whether or not a sentence is a factual claim. Only respond with Yes or No\",},\n",
    "    {\"role\": \"user\", \"content\": \"Is the following sentence a factual claim? __SENTENCE__\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# https://hippocampus-garden.com/tiny_llama_kto_lora/\n",
    "# https://huggingface.co/docs/trl/v0.8.1/en/kto_trainer\n",
    "Claimbuster = pd.read_json('../data/Claimbuster/train.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# KTOTrainer expects a training dataset with prompt, completion, and label\n",
    "# PROMPT FORMAT: [ { \"content\": \"Q:Question: how old julio cesar chavez when he fought de la hoya I found the following answer on Google: He holds records for most successful consecutive defenses of world titles (27), most title fights (37), most title-fight victories (31) and he is after Joe Louis with (23) for most title defenses won by knockout (21). Is that a correct answer? Yes or no.\\nA:\", \"role\": \"user\" } ]\n",
    "# COMPLETION FORMAT: [ { \"content\": \"The best answer for the entity related to 'James G. Roudebush' with the relationship of 'occupation' is: surgeon.\", \"role\": \"assistant\" } ]\n",
    "train_dataset = Claimbuster.copy(deep=True)\n",
    "train_dataset['completion'] = train_dataset['label'].apply(lambda x: [{\"role\": \"assistant\", \"content\": \"Yes\"}] if x == 1 else [{\"role\": \"assistant\", \"content\": \"No\"}])\n",
    "train_dataset['prompt'] = train_dataset['text'].apply(lambda x: [{\"role\": \"user\", \"content\": f\"Is the following sentence a factual claim? {x}\"}])\n",
    "train_dataset['label'] = True\n",
    "train_dataset = train_dataset.filter(items=['prompt','completion','label']).head(2)\n",
    "train_dataset.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'user', 'content': 'Is the following...</td>\n",
       "      <td>[{'role': 'assistant', 'content': 'Yes'}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'user', 'content': 'Is the following...</td>\n",
       "      <td>[{'role': 'assistant', 'content': 'Yes'}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [{'role': 'user', 'content': 'Is the following...   \n",
       "1  [{'role': 'user', 'content': 'Is the following...   \n",
       "\n",
       "                                  completion  label  \n",
       "0  [{'role': 'assistant', 'content': 'Yes'}]   True  \n",
       "1  [{'role': 'assistant', 'content': 'Yes'}]   True  "
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "td = Dataset.from_pandas(train_dataset)\n",
    "td"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion', 'label'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "training_args = KTOConfig(output_dir=\"..assets/finetuned-models/Llama-3.2-1B-Instruct-KTO\", logging_steps=10)\n",
    "trainer = KTOTrainer(model=model, args=training_args, processing_class=tokenizer, train_dataset=td)\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/miniconda3/envs/claim-extraction/lib/python3.13/site-packages/trl/trainer/kto_trainer.py:521: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your KTOConfig we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Extracting prompt from train dataset: 100%|██████████| 2/2 [00:00<00:00, 230.49 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 2/2 [00:00<00:00, 57.56 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 2/2 [00:00<00:00, 216.45 examples/s]\n",
      "Processing tokenized train dataset: 100%|██████████| 2/2 [00:00<00:00, 253.72 examples/s]\n",
      "Extracting KL train dataset: 100%|██████████| 2/2 [00:00<00:00, 328.99 examples/s]\n",
      "Processing tokenized train KL dataset: 100%|██████████| 2/2 [00:00<00:00, 225.51 examples/s]\n",
      "/opt/miniconda3/envs/claim-extraction/lib/python3.13/site-packages/trl/trainer/kto_trainer.py:726: UserWarning: You have different amounts of desirable/positive and undesirable/negative examples but the weights on the desirable and undesirable losses don't seem to be in an ideal range. Based on your data, we recommend EITHER desirable_weight in [0.5, 0.67] or undesirable_weight in [1.5, 2.0] (but NOT BOTH). See the documentation on how to optimally set these weights.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 03:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.5, metrics={'train_runtime': 271.1789, 'train_samples_per_second': 0.022, 'train_steps_per_second': 0.011, 'total_flos': 0.0, 'train_loss': 0.5, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# How to load a pre-trained model\n",
    "\n",
    "adapter_path = \"..assets/finetuned-models/Llama-3.2-1B-Instruct-KTO\"\n",
    "model_trained = AutoModelForCausalLM.from_pretrained(\n",
    "    adapter_path, use_safetensors=True\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a yes/no answering bot. Only respond to questions with Yes or No\",},\n",
    "    {\"role\": \"user\", \"content\": \"Is the capital of New York state New York City?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "]\n",
    "chat_template_input_ids = tokenizer.apply_chat_template(messages, tokenize=True, continue_final_message=True, add_generation_prompt=False, return_tensors=\"pt\")\n",
    "chat_template_input_ids = chat_template_input_ids[0, :-1].reshape(1,-1)\n",
    "\n",
    "print(tokenizer.batch_decode(model_trained.generate(chat_template_input_ids, max_new_tokens = 10))[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 06 Apr 2025\n",
      "\n",
      "You are a yes/no answering bot. Only respond to questions with Yes or No<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Is the capital of New York state New York City?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "No<|eot_id|>\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.13.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.13.2 64-bit ('claim-extraction': conda)"
  },
  "interpreter": {
   "hash": "6b023f274101c0d83a2338600e52d2429e6f2c6f40deb617cd262127fbe3c9bb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}